{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advanced Deep Learning with Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zu2isPZlBlv"
      },
      "source": [
        "# Advanced Deep Learning with Keras\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_OLCWn_jFhZ"
      },
      "source": [
        "# Course Description\r\n",
        "\r\n",
        "This course shows you how to solve a variety of problems using the versatile Keras functional API. You will start with simple, multi-layer dense networks (also known as multi-layer perceptrons), and continue on to more complicated architectures. The course will cover how to build models with multiple inputs and a single output, as well as how to share weights between layers in a model. We will also cover advanced topics such as category embeddings and multiple-output networks. If you've ever wanted to train a network that does both classification and regression, then this course is for you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLkrYAedjgVt"
      },
      "source": [
        "# 1. The Keras Functional API\r\n",
        "\r\n",
        "In this chapter, you'll become familiar with the basics of the Keras functional API. You'll build a simple functional network using functional building blocks, fit it to data, and make predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTwhbrFRnuym"
      },
      "source": [
        "### Keras input and dense layers (Video)\r\n",
        "\r\n",
        "Transcript:\r\n",
        "\r\n",
        "1. Keras input and dense layers\r\n",
        "Hi! I'm Zach Deane-Mayer, and in this course, I'll be teaching you advanced deep learning concepts using the keras functional API. You will learn how to build functional keras models, including advanced topics such as shared layers, categorical embeddings, multiple inputs, and multiple outputs. The keras functional API is extremely simple, yet immensely powerful. By the end of this class, you will build a model that is capable of solving a regression and a classification problem at the same time.\r\n",
        "\r\n",
        "2. Course outline\r\n",
        "Chapter 1 is a refresher on building simple models, where you will learn to use the keras functional API. In chapter 2, you will build a keras model with 2 inputs. In chapter 3, you will learn how to generalize your 2-input model to 3 or more inputs. And finally, in chapter 4, you will build models with multiple outputs that can solve multiple problems.\r\n",
        "\r\n",
        "3. Course Datasets: College basketball data, 1989-2017\r\n",
        "You will be using two datasets of college basketball games from American colleges. The first dataset is from the regular season and has the following data: the IDs of the 2 teams that played, whether the first team was home or away, whether the first team won or lost the game, and by how many points the first team won or lost. For the tournament dataset, you also have the tournament \"seed\", which is a pre-tournament ranking for each team. These seeds range from 1 to 16, where the best 4 teams get a seed of 1, and the worst 4 teams get a seed of 16. You will use the difference in the two team's seeds as an input to your model.\r\n",
        "\r\n",
        "4. Course Datasets: College basketball data, 1989-2017\r\n",
        "Here are the first five rows of both the datasets. You can see that the team variables are encoded as integers, and the tournament dataset has one additional column: the difference between the tournament seeds for both teams. Other than the seed difference, the two datasets have identical columns. Within a given year, a team's roster stays relatively constant, but between years it can change a lot, as seniors graduate, and freshmen start. Therefore, for every year, each school is given a unique integer ID.\r\n",
        "\r\n",
        "5. Inputs and outputs\r\n",
        "Keras models at their simplest, are fundamentally composed of 2 parts: an input layer and an output layer.\r\n",
        "\r\n",
        "6. Inputs\r\n",
        "To start, I'll define a very simple keras model, which only expects a single input. I specify this using the Input() function from the keras.layers module. The number of columns in the input is specified using the shape parameter. This tells the model how much data to expect. Note that the shape argument expects a tuple.\r\n",
        "\r\n",
        "7. Inputs\r\n",
        "The Input function returns a \"tensor.\" If you print this tensor, you'll see that it is a tf.Tensor object, which indicates it is ready to be used by our model as input.\r\n",
        "\r\n",
        "8. Outputs\r\n",
        "Now that we've defined our input layer, let's define the output layer. Outputs in keras are most commonly a single dense layer, which specifies the shape of the expected output. In this case, we are expecting our model to predict a single value, so we pass one unit to the dense layer.\r\n",
        "\r\n",
        "9. Outputs\r\n",
        "If you print the output layer, the result is NOT a tensorflow tensor. It is a function, which takes a tensor as input and produces a tensor as output. The difference between layers and tensors is key to understanding the keras functional API. Layers are used to construct a deep learning model, and tensors are used to define the data flow through the model.\r\n",
        "\r\n",
        "10. Connecting inputs to outputs\r\n",
        "In this case, the input layer defines a tensor, which we pass to the output_layer() function.\r\n",
        "\r\n",
        "11. Connecting inputs to outputs\r\n",
        "The final output of our model is a tensor.\r\n",
        "\r\n",
        "12. Let's practice!\r\n",
        "It's time for you to build some layers!\r\n",
        "\r\n",
        "Note: PDF available in the same folder chapter1\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb_-cDZypjue"
      },
      "source": [
        "### Input layers\r\n",
        "\r\n",
        "The first step in creating a neural network model is to define the Input layer. This layer takes in raw data, usually in the form of numpy arrays. The shape of the Input layer defines how many variables your neural network will use. For example, if the input data has 10 columns, you define an Input layer with a shape of (10,).\r\n",
        "\r\n",
        "In this case, you are only using one input in your network.\r\n",
        "\r\n",
        "This course touches on a lot of concepts you may have forgotten, so if you ever need a quick refresher, download the [Keras Cheat Sheet](https://datacamp-community-prod.s3.amazonaws.com/94fc681d-5422-40cb-a129-2218e9522f17) and keep it handy!\r\n",
        "\r\n",
        "```\r\n",
        "# Import Input from keras.layers\r\n",
        "from keras.layers import Input\r\n",
        "# Create an input layer of shape 1\r\n",
        "input_tensor = Input(shape=(1,))\r\n",
        "```\r\n",
        "*Great! Remember that the input layer allows your model to load data.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DksQueaiq0qX"
      },
      "source": [
        "### Dense layers\r\n",
        "\r\n",
        "Once you have an Input layer, the next step is to add a Dense layer.\r\n",
        "\r\n",
        "Dense layers learn a weight matrix, where the first dimension of the matrix is the dimension of the input data, and the second dimension is the dimension of the output data. Recall that your Input layer has a shape of 1. In this case, your output layer will also have a shape of 1. This means that the Dense layer will learn a 1x1 weight matrix.\r\n",
        "\r\n",
        "In this exercise, you will add a dense layer to your model, after the input layer.\r\n",
        "\r\n",
        "```\r\n",
        "# Load layers\r\n",
        "from keras.layers import Input, Dense\r\n",
        "\r\n",
        "# Input layer\r\n",
        "input_tensor = Input(shape=(1,))\r\n",
        "\r\n",
        "# Dense layer\r\n",
        "output_layer = Dense(1)\r\n",
        "\r\n",
        "# Connect the dense layer to the input_tensor\r\n",
        "output_tensor = output_layer(input_tensor)\r\n",
        "```\r\n",
        "*Nice job! This network will take the input, apply a linear coefficient to it, and return the result.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRgA-lYfrctD"
      },
      "source": [
        "# Output layers\r\n",
        "\r\n",
        "Output layers are simply Dense layers! Output layers are used to reduce the dimension of the inputs to the dimension of the outputs. You'll learn more about output dimensions in chapter 4, but for now, you'll always use a single output in your neural networks, which is equivalent to Dense(1) or a dense layer with a single unit.\r\n",
        "\r\n",
        "```\r\n",
        "# Load layers\r\n",
        "from keras.layers import Input, Dense\r\n",
        "\r\n",
        "# Input layer\r\n",
        "input_tensor = Input(shape=(1,))\r\n",
        "\r\n",
        "# Create a dense layer and connect the dense layer to the input_tensor in one step\r\n",
        "# Note that we did this in 2 steps in the previous exercise, but are doing it in one step now\r\n",
        "output_tensor = Dense(1)(input_tensor)\r\n",
        "```\r\n",
        "*The output layer allows your model to make predictions.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoJQ8enfsMJX"
      },
      "source": [
        "### Build and compile a model (Video)\r\n",
        "\r\n",
        "Transcript:\r\n",
        "\r\n",
        "1. Keras input and dense layers\r\n",
        "Hi! I'm Zach Deane-Mayer, and in this course, I'll be teaching you advanced deep learning concepts using the keras functional API. You will learn how to build functional keras models, including advanced topics such as shared layers, categorical embeddings, multiple inputs, and multiple outputs. The keras functional API is extremely simple, yet immensely powerful. By the end of this class, you will build a model that is capable of solving a regression and a classification problem at the same time.\r\n",
        "\r\n",
        "2. Course outline\r\n",
        "Chapter 1 is a refresher on building simple models, where you will learn to use the keras functional API. In chapter 2, you will build a keras model with 2 inputs. In chapter 3, you will learn how to generalize your 2-input model to 3 or more inputs. And finally, in chapter 4, you will build models with multiple outputs that can solve multiple problems.\r\n",
        "\r\n",
        "3. Course Datasets: College basketball data, 1989-2017\r\n",
        "You will be using two datasets of college basketball games from American colleges. The first dataset is from the regular season and has the following data: the IDs of the 2 teams that played, whether the first team was home or away, whether the first team won or lost the game, and by how many points the first team won or lost. For the tournament dataset, you also have the tournament \"seed\", which is a pre-tournament ranking for each team. These seeds range from 1 to 16, where the best 4 teams get a seed of 1, and the worst 4 teams get a seed of 16. You will use the difference in the two team's seeds as an input to your model.\r\n",
        "\r\n",
        "4. Course Datasets: College basketball data, 1989-2017\r\n",
        "Here are the first five rows of both the datasets. You can see that the team variables are encoded as integers, and the tournament dataset has one additional column: the difference between the tournament seeds for both teams. Other than the seed difference, the two datasets have identical columns. Within a given year, a team's roster stays relatively constant, but between years it can change a lot, as seniors graduate, and freshmen start. Therefore, for every year, each school is given a unique integer ID.\r\n",
        "\r\n",
        "5. Inputs and outputs\r\n",
        "Keras models at their simplest, are fundamentally composed of 2 parts: an input layer and an output layer.\r\n",
        "\r\n",
        "6. Inputs\r\n",
        "To start, I'll define a very simple keras model, which only expects a single input. I specify this using the Input() function from the keras.layers module. The number of columns in the input is specified using the shape parameter. This tells the model how much data to expect. Note that the shape argument expects a tuple.\r\n",
        "\r\n",
        "7. Inputs\r\n",
        "The Input function returns a \"tensor.\" If you print this tensor, you'll see that it is a tf.Tensor object, which indicates it is ready to be used by our model as input.\r\n",
        "\r\n",
        "8. Outputs\r\n",
        "Now that we've defined our input layer, let's define the output layer. Outputs in keras are most commonly a single dense layer, which specifies the shape of the expected output. In this case, we are expecting our model to predict a single value, so we pass one unit to the dense layer.\r\n",
        "\r\n",
        "9. Outputs\r\n",
        "If you print the output layer, the result is NOT a tensorflow tensor. It is a function, which takes a tensor as input and produces a tensor as output. The difference between layers and tensors is key to understanding the keras functional API. Layers are used to construct a deep learning model, and tensors are used to define the data flow through the model.\r\n",
        "\r\n",
        "10. Connecting inputs to outputs\r\n",
        "In this case, the input layer defines a tensor, which we pass to the output_layer() function.\r\n",
        "\r\n",
        "11. Connecting inputs to outputs\r\n",
        "The final output of our model is a tensor.\r\n",
        "\r\n",
        "12. Let's practice!\r\n",
        "It's time for you to build some layers!\r\n",
        "\r\n",
        "Note: PDF available in the same folder - chapter1-1\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIz290xAsnhN"
      },
      "source": [
        "### Build a model\r\n",
        "\r\n",
        "Once you've defined an input layer and an output layer, you can build a Keras model. The model object is how you tell Keras where the model starts and stops: where data comes in and where predictions come out.\r\n",
        "\r\n",
        "```\r\n",
        "# Input/dense/output layers\r\n",
        "from keras.layers import Input, Dense\r\n",
        "input_tensor = Input(shape=(1,))\r\n",
        "output_tensor = Dense(1)(input_tensor)\r\n",
        "\r\n",
        "# Build the model\r\n",
        "from keras.models import Model\r\n",
        "model = Model(input_tensor, output_tensor)\r\n",
        "```\r\n",
        "*This model is a complete neural network, ready to learn from data and make prediction.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOi-u7RJuTvc"
      },
      "source": [
        "### Compile a model\r\n",
        "\r\n",
        "The final step in creating a model is compiling it. Now that you've created a model, you have to compile it before you can fit it to data. This finalizes your model, freezes all its settings, and prepares it to meet some data!\r\n",
        "\r\n",
        "During compilation, you specify the optimizer to use for fitting the model to the data, and a loss function. 'adam' is a good default optimizer to use, and will generally work well. Loss function depends on the problem at hand. Mean squared error is a common loss function and will optimize for predicting the mean, as is done in least squares regression.\r\n",
        "\r\n",
        "Mean absolute error optimizes for the median and is used in quantile regression. For this dataset, 'mean_absolute_error' works pretty well, so use it as your loss function.\r\n",
        "\r\n",
        "```\r\n",
        "# Compile the model\r\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\r\n",
        "```\r\n",
        "*Compiling a model is the final step before fitting it.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-_cg-_hvlpD"
      },
      "source": [
        "### Visualize a model\r\n",
        "\r\n",
        "Now that you've compiled the model, take a look a the result of your hard work! You can do this by looking at the model summary, as well as its plot.\r\n",
        "\r\n",
        "The summary will tell you the names of the layers, as well as how many units they have and how many parameters are in the model.\r\n",
        "\r\n",
        "The plot will show how the layers connect to each other.\r\n",
        "\r\n",
        "```\r\n",
        "# Import the plotting function\r\n",
        "from keras.utils import plot_model\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# Summarize the model\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# Plot the model\r\n",
        "plot_model(model, to_file='model.png')\r\n",
        "\r\n",
        "# Display the image\r\n",
        "data = plt.imread('model.png')\r\n",
        "plt.imshow(data)\r\n",
        "plt.show()\r\n",
        "```\r\n",
        "*It turns out neural networks aren't really black boxes after all!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua9zK_9jwaKJ"
      },
      "source": [
        "### Fit and evaluate a model (Video)\r\n",
        "\r\n",
        "Transcript:\r\n",
        "\r\n",
        "1. Keras input and dense layers\r\n",
        "Hi! I'm Zach Deane-Mayer, and in this course, I'll be teaching you advanced deep learning concepts using the keras functional API. You will learn how to build functional keras models, including advanced topics such as shared layers, categorical embeddings, multiple inputs, and multiple outputs. The keras functional API is extremely simple, yet immensely powerful. By the end of this class, you will build a model that is capable of solving a regression and a classification problem at the same time.\r\n",
        "\r\n",
        "2. Course outline\r\n",
        "Chapter 1 is a refresher on building simple models, where you will learn to use the keras functional API. In chapter 2, you will build a keras model with 2 inputs. In chapter 3, you will learn how to generalize your 2-input model to 3 or more inputs. And finally, in chapter 4, you will build models with multiple outputs that can solve multiple problems.\r\n",
        "\r\n",
        "3. Course Datasets: College basketball data, 1989-2017\r\n",
        "You will be using two datasets of college basketball games from American colleges. The first dataset is from the regular season and has the following data: the IDs of the 2 teams that played, whether the first team was home or away, whether the first team won or lost the game, and by how many points the first team won or lost. For the tournament dataset, you also have the tournament \"seed\", which is a pre-tournament ranking for each team. These seeds range from 1 to 16, where the best 4 teams get a seed of 1, and the worst 4 teams get a seed of 16. You will use the difference in the two team's seeds as an input to your model.\r\n",
        "\r\n",
        "4. Course Datasets: College basketball data, 1989-2017\r\n",
        "Here are the first five rows of both the datasets. You can see that the team variables are encoded as integers, and the tournament dataset has one additional column: the difference between the tournament seeds for both teams. Other than the seed difference, the two datasets have identical columns. Within a given year, a team's roster stays relatively constant, but between years it can change a lot, as seniors graduate, and freshmen start. Therefore, for every year, each school is given a unique integer ID.\r\n",
        "\r\n",
        "5. Inputs and outputs\r\n",
        "Keras models at their simplest, are fundamentally composed of 2 parts: an input layer and an output layer.\r\n",
        "\r\n",
        "6. Inputs\r\n",
        "To start, I'll define a very simple keras model, which only expects a single input. I specify this using the Input() function from the keras.layers module. The number of columns in the input is specified using the shape parameter. This tells the model how much data to expect. Note that the shape argument expects a tuple.\r\n",
        "\r\n",
        "7. Inputs\r\n",
        "The Input function returns a \"tensor.\" If you print this tensor, you'll see that it is a tf.Tensor object, which indicates it is ready to be used by our model as input.\r\n",
        "\r\n",
        "8. Outputs\r\n",
        "Now that we've defined our input layer, let's define the output layer. Outputs in keras are most commonly a single dense layer, which specifies the shape of the expected output. In this case, we are expecting our model to predict a single value, so we pass one unit to the dense layer.\r\n",
        "\r\n",
        "9. Outputs\r\n",
        "If you print the output layer, the result is NOT a tensorflow tensor. It is a function, which takes a tensor as input and produces a tensor as output. The difference between layers and tensors is key to understanding the keras functional API. Layers are used to construct a deep learning model, and tensors are used to define the data flow through the model.\r\n",
        "\r\n",
        "10. Connecting inputs to outputs\r\n",
        "In this case, the input layer defines a tensor, which we pass to the output_layer() function.\r\n",
        "\r\n",
        "11. Connecting inputs to outputs\r\n",
        "The final output of our model is a tensor.\r\n",
        "\r\n",
        "12. Let's practice!\r\n",
        "It's time for you to build some layers!\r\n",
        "\r\n",
        "Note: PDF available in the same folder - chapter1-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_EvLg-0yV3S"
      },
      "source": [
        "### Fit the model to the tournament basketball data\r\n",
        "\r\n",
        "Now that the model is compiled, you are ready to fit it to some data!\r\n",
        "\r\n",
        "In this exercise, you'll use a dataset of scores from US College Basketball tournament games. Each row of the dataset has the team ids: team_1 and team_2, as integers. It also has the seed difference between the teams (seeds are assigned by the tournament committee and represent a ranking of how strong the teams are) and the score difference of the game (e.g. if team_1 wins by 5 points, the score difference is 5).\r\n",
        "\r\n",
        "To fit the model, you provide a matrix of X variables (in this case one column: the seed difference) and a matrix of Y variables (in this case one column: the score difference).\r\n",
        "\r\n",
        "The games_tourney DataFrame along with the compiled model object is available in your workspace.\r\n",
        "\r\n",
        "```\r\n",
        "# Now fit the model\r\n",
        "model.fit(games_tourney_train['seed_diff'], games_tourney_train['score_diff'],\r\n",
        "          epochs=1,\r\n",
        "          batch_size=128,\r\n",
        "          validation_split=.10,\r\n",
        "          verbose=True)\r\n",
        "```\r\n",
        "*Now your model has learned something about the basketball data!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWzDB5ElzOEk"
      },
      "source": [
        "### Evaluate the model on a test set\r\n",
        "\r\n",
        "After fitting the model, you can evaluate it on new data. You will give the model a new X matrix (also called test data), allow it to make predictions, and then compare to the known y variable (also called target data).\r\n",
        "\r\n",
        "In this case, you'll use data from the post-season tournament to evaluate your model. The tournament games happen after the regular season games you used to train our model, and are therefore a good evaluation of how well your model performs out-of-sample.\r\n",
        "\r\n",
        "The games_tourney_test DataFrame along with the fitted model object is available in your workspace.\r\n",
        "\r\n",
        "```\r\n",
        "# Load the X variable from the test data\r\n",
        "X_test = games_tourney_test['seed_diff']\r\n",
        "\r\n",
        "# Load the y variable from the test data\r\n",
        "y_test = games_tourney_test['score_diff']\r\n",
        "\r\n",
        "# Evaluate the model on the test data\r\n",
        "print(model.evaluate(X_test, y_test, verbose=False))\r\n",
        "```\r\n",
        "*Looks like your model makes pretty good predicitions!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fZSLYWij4ec"
      },
      "source": [
        "# 2. Two Input Networks Using Categorical Embeddings, Shared Layers, and Merge Layers\r\n",
        "\r\n",
        "In this chapter, you will build two-input networks that use categorical embeddings to represent high-cardinality data, shared layers to specify re-usable building blocks, and merge layers to join multiple inputs to a single output. By the end of this chapter, you will have the foundational building blocks for designing neural networks with complex data flows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjsTgew_057q"
      },
      "source": [
        "### Category embeddings (Video)\r\n",
        "\r\n",
        "Transcript: \r\n",
        "\r\n",
        "1. Keras input and dense layers\r\n",
        "Hi! I'm Zach Deane-Mayer, and in this course, I'll be teaching you advanced deep learning concepts using the keras functional API. You will learn how to build functional keras models, including advanced topics such as shared layers, categorical embeddings, multiple inputs, and multiple outputs. The keras functional API is extremely simple, yet immensely powerful. By the end of this class, you will build a model that is capable of solving a regression and a classification problem at the same time.\r\n",
        "\r\n",
        "2. Course outline\r\n",
        "Chapter 1 is a refresher on building simple models, where you will learn to use the keras functional API. In chapter 2, you will build a keras model with 2 inputs. In chapter 3, you will learn how to generalize your 2-input model to 3 or more inputs. And finally, in chapter 4, you will build models with multiple outputs that can solve multiple problems.\r\n",
        "\r\n",
        "3. Course Datasets: College basketball data, 1989-2017\r\n",
        "You will be using two datasets of college basketball games from American colleges. The first dataset is from the regular season and has the following data: the IDs of the 2 teams that played, whether the first team was home or away, whether the first team won or lost the game, and by how many points the first team won or lost. For the tournament dataset, you also have the tournament \"seed\", which is a pre-tournament ranking for each team. These seeds range from 1 to 16, where the best 4 teams get a seed of 1, and the worst 4 teams get a seed of 16. You will use the difference in the two team's seeds as an input to your model.\r\n",
        "\r\n",
        "4. Course Datasets: College basketball data, 1989-2017\r\n",
        "Here are the first five rows of both the datasets. You can see that the team variables are encoded as integers, and the tournament dataset has one additional column: the difference between the tournament seeds for both teams. Other than the seed difference, the two datasets have identical columns. Within a given year, a team's roster stays relatively constant, but between years it can change a lot, as seniors graduate, and freshmen start. Therefore, for every year, each school is given a unique integer ID.\r\n",
        "\r\n",
        "5. Inputs and outputs\r\n",
        "Keras models at their simplest, are fundamentally composed of 2 parts: an input layer and an output layer.\r\n",
        "\r\n",
        "6. Inputs\r\n",
        "To start, I'll define a very simple keras model, which only expects a single input. I specify this using the Input() function from the keras.layers module. The number of columns in the input is specified using the shape parameter. This tells the model how much data to expect. Note that the shape argument expects a tuple.\r\n",
        "\r\n",
        "7. Inputs\r\n",
        "The Input function returns a \"tensor.\" If you print this tensor, you'll see that it is a tf.Tensor object, which indicates it is ready to be used by our model as input.\r\n",
        "\r\n",
        "8. Outputs\r\n",
        "Now that we've defined our input layer, let's define the output layer. Outputs in keras are most commonly a single dense layer, which specifies the shape of the expected output. In this case, we are expecting our model to predict a single value, so we pass one unit to the dense layer.\r\n",
        "\r\n",
        "9. Outputs\r\n",
        "If you print the output layer, the result is NOT a tensorflow tensor. It is a function, which takes a tensor as input and produces a tensor as output. The difference between layers and tensors is key to understanding the keras functional API. Layers are used to construct a deep learning model, and tensors are used to define the data flow through the model.\r\n",
        "\r\n",
        "10. Connecting inputs to outputs\r\n",
        "In this case, the input layer defines a tensor, which we pass to the output_layer() function.\r\n",
        "\r\n",
        "11. Connecting inputs to outputs\r\n",
        "The final output of our model is a tensor.\r\n",
        "\r\n",
        "12. Let's practice!\r\n",
        "It's time for you to build some layers\r\n",
        "\r\n",
        "Note: PDF available in the same folder - chapter2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fuap1UC05zj"
      },
      "source": [
        "### Define team lookup\r\n",
        "\r\n",
        "Shared layers allow a model to use the same weight matrix for multiple steps. In this exercise, you will build a \"team strength\" layer that represents each team by a single number. You will use this number for both teams in the model. The model will learn a number for each team that works well both when the team is team_1 and when the team is team_2 in the input data.\r\n",
        "\r\n",
        "The games_season DataFrame is available in your workspace.\r\n",
        "```\r\n",
        "# Imports\r\n",
        "from keras.layers import Embedding\r\n",
        "from numpy import unique\r\n",
        "\r\n",
        "# Count the unique number of teams\r\n",
        "n_teams = unique(games_season['team_1']).shape[0]\r\n",
        "\r\n",
        "# Create an embedding layer\r\n",
        "team_lookup = Embedding(input_dim=n_teams,\r\n",
        "                        output_dim=1,\r\n",
        "                        input_length=1,\r\n",
        "                        name='Team-Strength')\r\n",
        "```\r\n",
        "*The embedding layer is a lot like a dictionary, but your model learns the values for each key.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-P5m0UD05ws"
      },
      "source": [
        "### Define team model\r\n",
        "\r\n",
        "The team strength lookup has three components: an input, an embedding layer, and a flatten layer that creates the output.\r\n",
        "\r\n",
        "If you wrap these three layers in a model with an input and output, you can re-use that stack of three layers at multiple places.\r\n",
        "\r\n",
        "Note again that the weights for all three layers will be shared everywhere we use them.\r\n",
        "\r\n",
        "```\r\n",
        "# Imports\r\n",
        "from keras.layers import Input, Embedding, Flatten\r\n",
        "from keras.models import Model\r\n",
        "\r\n",
        "# Create an input layer for the team ID\r\n",
        "teamid_in = Input(shape=(1,))\r\n",
        "\r\n",
        "# Lookup the input in the team strength embedding layer\r\n",
        "strength_lookup = team_lookup(teamid_in)\r\n",
        "\r\n",
        "# Flatten the output\r\n",
        "strength_lookup_flat = Flatten()(strength_lookup)\r\n",
        "\r\n",
        "# Combine the operations into a single, re-usable model\r\n",
        "team_strength_model = Model(teamid_in, strength_lookup_flat, name='Team-Strength-Model')\r\n",
        "```\r\n",
        "*The model will be reusable, so you can use it in two places in your final model.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkVSM5w005ty"
      },
      "source": [
        "### Shared layers (Video)\r\n",
        "\r\n",
        "Transcript:\r\n",
        "\r\n",
        "1. Shared layers\r\n",
        "In this chapter, you will create a model with two inputs: one for each team in the basketball dataset. However, you want these two teams to each use the same embedding layer you defined in the previous lesson. Accomplishing this requires a shared layer.\r\n",
        "\r\n",
        "2. Shared layers\r\n",
        "Shared layers are an advanced deep learning concept, and are only possible with the Keras functional API. They allow you to define an operation and then apply the exact same operation (with the exact same weights) on different inputs. In this model, we will share team rating for both inputs. The learned rating will be the same, whether it applies to team 1 or team 2.\r\n",
        "\r\n",
        "3. Shared layers\r\n",
        "To create a shared layer, you must first create two (or more) inputs, each of which will be passed to the shared layer. In this case, you will use two inputs.\r\n",
        "\r\n",
        "4. Shared layers\r\n",
        "Once you have two inputs, the magic of the Keras functional API becomes apparent. Recall from chapter 1 that the Dense() function returns a function as its output. This function, which Dense() outputs, takes a tensor as input and produces a tensor as output. You can use the same Dense() function to create a shared layer! Doing so is as simple as calling the function twice, with a different input tensor each time.\r\n",
        "\r\n",
        "5. Sharing multiple layers as a model\r\n",
        "Recall the category embedding model we made in the previous lesson. This model first embeds an input and then flattens it. You can also share models, not just layers. This is really cool and is part of what makes the functional API so useful. You can define modular components of models and then reuse them. We define an embedding layer and wrap it in a model. We then define 2 input tensors, and pass each one to the same model, producing 2 output tensors. This will use the same model, with the same layers and the same weights, for mapping each input to its corresponding output.\r\n",
        "\r\n",
        "6. Sharing multiple layers as a model\r\n",
        "In other words, you can take an arbitrary sequence of keras layers, and wrap them up in a model. Once you have a model, you can re-use that model to share that sequence of steps for different input layers.\r\n",
        "\r\n",
        "7. Let's practice!\r\n",
        "Now you will create a shared layer using the team strength embedding model you made in the previous lesson.\r\n",
        "\r\n",
        "Note: PDF available in the same folder - chapter2-1\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPg5lRZb05qe"
      },
      "source": [
        "### Defining two inputs\r\n",
        "\r\n",
        "In this exercise, you will define two input layers for the two teams in your model. This allows you to specify later in the model how the data from each team will be used differently.\r\n",
        "\r\n",
        "```\r\n",
        "# Load the input layer from keras.layers\r\n",
        "from keras.layers import Input\r\n",
        "\r\n",
        "# Input layer for team 1\r\n",
        "team_in_1 = Input(shape=(1,), name=\"Team-1-In\")\r\n",
        "\r\n",
        "# Separate input layer for team 2\r\n",
        "team_in_2 = Input(shape=(1,), name=\"Team-2-In\")\r\n",
        "```\r\n",
        "*These two inputs will be used later for the shared layer.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il9Njare05kx"
      },
      "source": [
        "### Lookup both inputs in the same model\r\n",
        "\r\n",
        "Now that you have a team strength model and an input layer for each team, you can lookup the team inputs in the shared team strength model. The two inputs will share the same weights.\r\n",
        "\r\n",
        "In this dataset, you have 10,888 unique teams. You want to learn a strength rating for each team, such that if any pair of teams plays each other, you can predict the score, even if those two teams have never played before. Furthermore, you want the strength rating to be the same, regardless of whether the team is the home team or the away team.\r\n",
        "\r\n",
        "To achieve this, you use a shared layer, defined by the re-usable model (team_strength_model()) you built in exercise 3 and the two input layers (team_in_1 and team_in_2) from the previous exercise, all of which are available in your workspace.\r\n",
        "\r\n",
        "```\r\n",
        "# Lookup team 1 in the team strength model\r\n",
        "team_1_strength = team_strength_model(team_in_1)\r\n",
        "\r\n",
        "# Lookup team 2 in the team strength model\r\n",
        "team_2_strength = team_strength_model(team_in_2)\r\n",
        "```\r\n",
        "*Now your model knows how strong each team is.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcQgO2Lf05dU"
      },
      "source": [
        "### Merge layers (Video)\r\n",
        "\r\n",
        "Transcript:\r\n",
        "\r\n",
        "1. Shared layers\r\n",
        "In this chapter, you will create a model with two inputs: one for each team in the basketball dataset. However, you want these two teams to each use the same embedding layer you defined in the previous lesson. Accomplishing this requires a shared layer.\r\n",
        "\r\n",
        "2. Shared layers\r\n",
        "Shared layers are an advanced deep learning concept, and are only possible with the Keras functional API. They allow you to define an operation and then apply the exact same operation (with the exact same weights) on different inputs. In this model, we will share team rating for both inputs. The learned rating will be the same, whether it applies to team 1 or team 2.\r\n",
        "\r\n",
        "3. Shared layers\r\n",
        "To create a shared layer, you must first create two (or more) inputs, each of which will be passed to the shared layer. In this case, you will use two inputs.\r\n",
        "\r\n",
        "4. Shared layers\r\n",
        "Once you have two inputs, the magic of the Keras functional API becomes apparent. Recall from chapter 1 that the Dense() function returns a function as its output. This function, which Dense() outputs, takes a tensor as input and produces a tensor as output. You can use the same Dense() function to create a shared layer! Doing so is as simple as calling the function twice, with a different input tensor each time.\r\n",
        "\r\n",
        "5. Sharing multiple layers as a model\r\n",
        "Recall the category embedding model we made in the previous lesson. This model first embeds an input and then flattens it. You can also share models, not just layers. This is really cool and is part of what makes the functional API so useful. You can define modular components of models and then reuse them. We define an embedding layer and wrap it in a model. We then define 2 input tensors, and pass each one to the same model, producing 2 output tensors. This will use the same model, with the same layers and the same weights, for mapping each input to its corresponding output.\r\n",
        "\r\n",
        "6. Sharing multiple layers as a model\r\n",
        "In other words, you can take an arbitrary sequence of keras layers, and wrap them up in a model. Once you have a model, you can re-use that model to share that sequence of steps for different input layers.\r\n",
        "\r\n",
        "7. Let's practice!\r\n",
        "Now you will create a shared layer using the team strength embedding model you made in the previous lesson.\r\n",
        "\r\n",
        "Note: PDF available in the same folder - chapter2-2\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5-tnd2405TP"
      },
      "source": [
        "### Output layer using shared layer\r\n",
        "\r\n",
        "Now that you've looked up how \"strong\" each team is, subtract the team strengths to determine which team is expected to win the game.\r\n",
        "\r\n",
        "This is a bit like the seeds that the tournament committee uses, which are also a measure of team strength. But rather than using seed differences to predict score differences, you'll use the difference of your own team strength model to predict score differences.\r\n",
        "\r\n",
        "The subtract layer will combine the weights from the two layers by subtracting them.\r\n",
        "\r\n",
        "```\r\n",
        "# Import the Subtract layer from keras\r\n",
        "from keras.layers import Subtract\r\n",
        "\r\n",
        "# Create a subtract layer using the inputs from the previous exercise\r\n",
        "score_diff = Subtract()([team_1_strength, team_2_strength])\r\n",
        "```\r\n",
        "*This setup subracts the team strength ratings to determine a winner.*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCQOq6fe91HY"
      },
      "source": [
        "### Model using two inputs and one output\r\n",
        "\r\n",
        "Now that you have your two inputs (team id 1 and team id 2) and output (score difference), you can wrap them up in a model so you can use it later for fitting to data and evaluating on new data.\r\n",
        "\r\n",
        "```\r\n",
        "# Imports\r\n",
        "from keras.layers import Subtract\r\n",
        "from keras.models import Model\r\n",
        "\r\n",
        "# Subtraction layer from previous exercise\r\n",
        "score_diff = Subtract()([team_1_strength, team_2_strength])\r\n",
        "\r\n",
        "# Create the model\r\n",
        "model = Model([team_in_1, team_in_2], score_diff)\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "model.compile(optimizer=\"adam\", loss=\"mean_absolute_error\")\r\n",
        "```\r\n",
        "*Now your model is finalized and ready to fit to data.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmO701s-05Fa"
      },
      "source": [
        "### Predict from your model (Video)\r\n",
        "\r\n",
        "Transcript:\r\n",
        "\r\n",
        "1. Shared layers\r\n",
        "In this chapter, you will create a model with two inputs: one for each team in the basketball dataset. However, you want these two teams to each use the same embedding layer you defined in the previous lesson. Accomplishing this requires a shared layer.\r\n",
        "\r\n",
        "2. Shared layers\r\n",
        "Shared layers are an advanced deep learning concept, and are only possible with the Keras functional API. They allow you to define an operation and then apply the exact same operation (with the exact same weights) on different inputs. In this model, we will share team rating for both inputs. The learned rating will be the same, whether it applies to team 1 or team 2.\r\n",
        "\r\n",
        "3. Shared layers\r\n",
        "To create a shared layer, you must first create two (or more) inputs, each of which will be passed to the shared layer. In this case, you will use two inputs.\r\n",
        "\r\n",
        "4. Shared layers\r\n",
        "Once you have two inputs, the magic of the Keras functional API becomes apparent. Recall from chapter 1 that the Dense() function returns a function as its output. This function, which Dense() outputs, takes a tensor as input and produces a tensor as output. You can use the same Dense() function to create a shared layer! Doing so is as simple as calling the function twice, with a different input tensor each time.\r\n",
        "\r\n",
        "5. Sharing multiple layers as a model\r\n",
        "Recall the category embedding model we made in the previous lesson. This model first embeds an input and then flattens it. You can also share models, not just layers. This is really cool and is part of what makes the functional API so useful. You can define modular components of models and then reuse them. We define an embedding layer and wrap it in a model. We then define 2 input tensors, and pass each one to the same model, producing 2 output tensors. This will use the same model, with the same layers and the same weights, for mapping each input to its corresponding output.\r\n",
        "\r\n",
        "6. Sharing multiple layers as a model\r\n",
        "In other words, you can take an arbitrary sequence of keras layers, and wrap them up in a model. Once you have a model, you can re-use that model to share that sequence of steps for different input layers.\r\n",
        "\r\n",
        "7. Let's practice!\r\n",
        "Now you will create a shared layer using the team strength embedding model you made in the previous lesson.\r\n",
        "\r\n",
        "Note: PDF available in the same folder - chapter2-3\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uIauY0i-3RT"
      },
      "source": [
        "### Fit the model to the regular season training data\r\n",
        "\r\n",
        "Now that you've defined a complete team strength model, you can fit it to the basketball data! Since your model has two inputs now, you need to pass the input data as a list.\r\n",
        "\r\n",
        "```\r\n",
        "# Get the team_1 column from the regular season data\r\n",
        "input_1 = games_season['team_1']\r\n",
        "\r\n",
        "# Get the team_2 column from the regular season data\r\n",
        "input_2 = games_season['team_2']\r\n",
        "\r\n",
        "# Fit the model to input 1 and 2, using score diff as a target\r\n",
        "model.fit([input_1,input_2],\r\n",
        "          games_season['score_diff'],\r\n",
        "          epochs=1,\r\n",
        "          batch_size=2048,\r\n",
        "          validation_split=.10,\r\n",
        "          verbose=True)\r\n",
        "```\r\n",
        "*ow our model has learned a strength rating for every team.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuID36LpAOLL"
      },
      "source": [
        "### Evaluate the model on the tournament test data\r\n",
        "\r\n",
        "The model you fit to the regular season data (model) in the previous exercise and the tournament dataset (games_tourney) are available in your workspace.\r\n",
        "\r\n",
        "In this exercise, you will evaluate the model on this new dataset. This evaluation will tell you how well you can predict the tournament games, based on a model trained with the regular season data. This is interesting because many teams play each other in the tournament that did not play in the regular season, so this is a very good check that your model is not overfitting.\r\n",
        "\r\n",
        "```\r\n",
        "# Get team_1 from the tournament data\r\n",
        "input_1 = games_tourney['team_1']\r\n",
        "\r\n",
        "# Get team_2 from the tournament data\r\n",
        "input_2 = games_tourney['team_2']\r\n",
        "\r\n",
        "# Evaluate the model using these inputs\r\n",
        "print(model.evaluate([input_1, input_2], games_tourney['score_diff'], verbose=False))\r\n",
        "```\r\n",
        "*Great job! Its time to move on to models with more than two inputs.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbnFqHLwj4pD"
      },
      "source": [
        "# 3. Multiple Inputs: 3 Inputs (and Beyond!)\r\n",
        "\r\n",
        "In this chapter, you will extend your 2-input model to 3 inputs, and learn how to use Keras' summary and plot functions to understand the parameters and topology of your neural networks. By the end of the chapter, you will understand how to extend a 2-input model to 3 inputs and beyond.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIqtoYeNBZhB"
      },
      "source": [
        "### Three-input models (Video)\r\n",
        "\r\n",
        "Transcript:\r\n",
        "\r\n",
        "1. Shared layers\r\n",
        "In this chapter, you will create a model with two inputs: one for each team in the basketball dataset. However, you want these two teams to each use the same embedding layer you defined in the previous lesson. Accomplishing this requires a shared layer.\r\n",
        "\r\n",
        "2. Shared layers\r\n",
        "Shared layers are an advanced deep learning concept, and are only possible with the Keras functional API. They allow you to define an operation and then apply the exact same operation (with the exact same weights) on different inputs. In this model, we will share team rating for both inputs. The learned rating will be the same, whether it applies to team 1 or team 2.\r\n",
        "\r\n",
        "3. Shared layers\r\n",
        "To create a shared layer, you must first create two (or more) inputs, each of which will be passed to the shared layer. In this case, you will use two inputs.\r\n",
        "\r\n",
        "4. Shared layers\r\n",
        "Once you have two inputs, the magic of the Keras functional API becomes apparent. Recall from chapter 1 that the Dense() function returns a function as its output. This function, which Dense() outputs, takes a tensor as input and produces a tensor as output. You can use the same Dense() function to create a shared layer! Doing so is as simple as calling the function twice, with a different input tensor each time.\r\n",
        "\r\n",
        "5. Sharing multiple layers as a model\r\n",
        "Recall the category embedding model we made in the previous lesson. This model first embeds an input and then flattens it. You can also share models, not just layers. This is really cool and is part of what makes the functional API so useful. You can define modular components of models and then reuse them. We define an embedding layer and wrap it in a model. We then define 2 input tensors, and pass each one to the same model, producing 2 output tensors. This will use the same model, with the same layers and the same weights, for mapping each input to its corresponding output.\r\n",
        "\r\n",
        "6. Sharing multiple layers as a model\r\n",
        "In other words, you can take an arbitrary sequence of keras layers, and wrap them up in a model. Once you have a model, you can re-use that model to share that sequence of steps for different input layers.\r\n",
        "\r\n",
        "7. Let's practice!\r\n",
        "Now you will create a shared layer using the team strength embedding model you made in the previous lesson.\r\n",
        "\r\n",
        "Note: PDF available in the same folder - chapter3\r\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5T_SiejBZeK"
      },
      "source": [
        "### Make an input layer for home vs. away\r\n",
        "\r\n",
        "Now you will make an improvement to the model you used in the previous chapter for regular season games. You know there is a well-documented home-team advantage in basketball, so you will add a new input to your model to capture this effect.\r\n",
        "\r\n",
        "This model will have three inputs: team_id_1, team_id_2, and home. The team IDs will be integers that you look up in your team strength model from the previous chapter, and home will be a binary variable, 1 if team_1 is playing at home, 0 if they are not.\r\n",
        "\r\n",
        "The team_strength_model you used in the previous chapter has been loaded into your workspace. After applying it to each input, use a Concatenate layer to join the two team strengths and with the home vs away variable, and pass the result to a Dense layer.\r\n",
        "\r\n",
        "```\r\n",
        "# Create an Input for each team\r\n",
        "team_in_1 = Input(shape=(1,), name='Team-1-In')\r\n",
        "team_in_2 = Input(shape=(1,), name='Team-2-In')\r\n",
        "\r\n",
        "# Create an input for home vs away\r\n",
        "home_in = Input(shape=(1,), name='Home-In')\r\n",
        "\r\n",
        "# Lookup the team inputs in the team strength model\r\n",
        "team_1_strength = team_strength_model(team_in_1)\r\n",
        "team_2_strength = team_strength_model(team_in_2)\r\n",
        "# Combine the team strengths with the home input using a Concatenate layer, then add a Dense layer\r\n",
        "out = Concatenate()([team_1_strength, team_2_strength, home_in])\r\n",
        "out = Dense(1)(out)\r\n",
        "```\r\n",
        "*Now you have a model with 3 inputs!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPuGjEhcBYdK"
      },
      "source": [
        "### Make a model and compile it\r\n",
        "\r\n",
        "Now that you've input and output layers for the 3-input model, wrap them up in a Keras model class, and then compile the model, so you can fit it to data and use it to make predictions on new data.\r\n",
        "\r\n",
        "```\r\n",
        "# Import the model class\r\n",
        "from keras.models import Model\r\n",
        "\r\n",
        "# Make a Model\r\n",
        "model = Model([team_in_1, team_in_2, home_in], out)\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\r\n",
        "```\r\n",
        "*Now our 3-input model is ready to meet some data!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIbeHNbHBYGd"
      },
      "source": [
        "### Fit the model and evaluate\r\n",
        "\r\n",
        "Now that you've defined a new model, fit it to the regular season basketball data.\r\n",
        "\r\n",
        "Use the model you fit in the previous exercise (which was trained on the regular season data) and evaluate the model on data for tournament games (games_tourney).\r\n",
        "\r\n",
        "```\r\n",
        "# Fit the model to the games_season dataset\r\n",
        "model.fit([games_season['team_1'], games_season['team_2'], games_season['home']],\r\n",
        "          games_season['score_diff'],\r\n",
        "          epochs=1,\r\n",
        "          verbose=True,\r\n",
        "          validation_split=.10,\r\n",
        "          batch_size=2048)\r\n",
        "\r\n",
        "# Evaluate the model on the games_tourney dataset\r\n",
        "print(model.evaluate([games_tourney['team_1'], games_tourney['team_2'], games_tourney['home']], games_tourney['score_diff'], verbose=False))\r\n",
        "```\r\n",
        "*Well done! Its time to further explore this model.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDLAhimfBYDG"
      },
      "source": [
        "### Well done! Its time to further explore this model (Video)\r\n",
        "\r\n",
        "Transcript:\r\n",
        "\r\n",
        "1. Shared layers\r\n",
        "In this chapter, you will create a model with two inputs: one for each team in the basketball dataset. However, you want these two teams to each use the same embedding layer you defined in the previous lesson. Accomplishing this requires a shared layer.\r\n",
        "\r\n",
        "2. Shared layers\r\n",
        "Shared layers are an advanced deep learning concept, and are only possible with the Keras functional API. They allow you to define an operation and then apply the exact same operation (with the exact same weights) on different inputs. In this model, we will share team rating for both inputs. The learned rating will be the same, whether it applies to team 1 or team 2.\r\n",
        "\r\n",
        "3. Shared layers\r\n",
        "To create a shared layer, you must first create two (or more) inputs, each of which will be passed to the shared layer. In this case, you will use two inputs.\r\n",
        "\r\n",
        "4. Shared layers\r\n",
        "Once you have two inputs, the magic of the Keras functional API becomes apparent. Recall from chapter 1 that the Dense() function returns a function as its output. This function, which Dense() outputs, takes a tensor as input and produces a tensor as output. You can use the same Dense() function to create a shared layer! Doing so is as simple as calling the function twice, with a different input tensor each time.\r\n",
        "\r\n",
        "5. Sharing multiple layers as a model\r\n",
        "Recall the category embedding model we made in the previous lesson. This model first embeds an input and then flattens it. You can also share models, not just layers. This is really cool and is part of what makes the functional API so useful. You can define modular components of models and then reuse them. We define an embedding layer and wrap it in a model. We then define 2 input tensors, and pass each one to the same model, producing 2 output tensors. This will use the same model, with the same layers and the same weights, for mapping each input to its corresponding output.\r\n",
        "\r\n",
        "6. Sharing multiple layers as a model\r\n",
        "In other words, you can take an arbitrary sequence of keras layers, and wrap them up in a model. Once you have a model, you can re-use that model to share that sequence of steps for different input layers.\r\n",
        "\r\n",
        "7. Let's practice!\r\n",
        "Now you will create a shared layer using the team strength embedding model you made in the previous lesson.\r\n",
        "\r\n",
        "Note: PDF available in the same folder - chapter3-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ-LzwbiBYAj"
      },
      "source": [
        "### Model summaries\r\n",
        "\r\n",
        "In this exercise, you will take a closer look at the summary of one of your 3-input models available in your workspace as model. Note how many layers the model has, how many parameters it has, and how many of those parameters are trainable/non-trainable.\r\n",
        "\r\n",
        "```\r\n",
        "model.summary()\r\n",
        "\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wravolYtBX9i"
      },
      "source": [
        "### Plotting models\r\n",
        "\r\n",
        "In addition to summarizing your model, you can also plot your model to get a more intuitive sense of it. Your model is available in the workspace.\r\n",
        "\r\n",
        "```\r\n",
        "# Imports\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from keras.utils import plot_model\r\n",
        "\r\n",
        "# Plot the model\r\n",
        "plot_model(model, to_file='model.png')\r\n",
        "\r\n",
        "# Display the image\r\n",
        "data = plt.imread('model.png')\r\n",
        "plt.imshow(data)\r\n",
        "plt.show()\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHF5MCIRBX6P"
      },
      "source": [
        "### Stacking models (Video)\r\n",
        "\r\n",
        "Transcript:\r\n",
        "\r\n",
        "1. Shared layers\r\n",
        "In this chapter, you will create a model with two inputs: one for each team in the basketball dataset. However, you want these two teams to each use the same embedding layer you defined in the previous lesson. Accomplishing this requires a shared layer.\r\n",
        "\r\n",
        "2. Shared layers\r\n",
        "Shared layers are an advanced deep learning concept, and are only possible with the Keras functional API. They allow you to define an operation and then apply the exact same operation (with the exact same weights) on different inputs. In this model, we will share team rating for both inputs. The learned rating will be the same, whether it applies to team 1 or team 2.\r\n",
        "\r\n",
        "3. Shared layers\r\n",
        "To create a shared layer, you must first create two (or more) inputs, each of which will be passed to the shared layer. In this case, you will use two inputs.\r\n",
        "\r\n",
        "4. Shared layers\r\n",
        "Once you have two inputs, the magic of the Keras functional API becomes apparent. Recall from chapter 1 that the Dense() function returns a function as its output. This function, which Dense() outputs, takes a tensor as input and produces a tensor as output. You can use the same Dense() function to create a shared layer! Doing so is as simple as calling the function twice, with a different input tensor each time.\r\n",
        "\r\n",
        "5. Sharing multiple layers as a model\r\n",
        "Recall the category embedding model we made in the previous lesson. This model first embeds an input and then flattens it. You can also share models, not just layers. This is really cool and is part of what makes the functional API so useful. You can define modular components of models and then reuse them. We define an embedding layer and wrap it in a model. We then define 2 input tensors, and pass each one to the same model, producing 2 output tensors. This will use the same model, with the same layers and the same weights, for mapping each input to its corresponding output.\r\n",
        "\r\n",
        "6. Sharing multiple layers as a model\r\n",
        "In other words, you can take an arbitrary sequence of keras layers, and wrap them up in a model. Once you have a model, you can re-use that model to share that sequence of steps for different input layers.\r\n",
        "\r\n",
        "7. Let's practice!\r\n",
        "Now you will create a shared layer using the team strength embedding model you made in the previous lesson.\r\n",
        "\r\n",
        "Note: PDF available in the same folder - chapter3-2\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcNERT-sIEp_"
      },
      "source": [
        "### Add the model predictions to the tournament data\r\n",
        "\r\n",
        "In lesson 1 of this chapter, you used the regular season model to make predictions on the tournament dataset, and got pretty good results! Try to improve your predictions for the tournament by modeling it specifically.\r\n",
        "\r\n",
        "You'll use the prediction from the regular season model as an input to the tournament model. This is a form of \"model stacking.\"\r\n",
        "\r\n",
        "To start, take the regular season model from the previous lesson, and predict on the tournament data. Add this prediction to the tournament data as a new column.\r\n",
        "\r\n",
        "```\r\n",
        "# Predict\r\n",
        "games_tourney['pred'] = model.predict([games_tourney['team_1'],\r\n",
        "                                             games_tourney['team_2'],\r\n",
        "                                             games_tourney['home']])\r\n",
        "```\r\n",
        "*Now you can try building a model for the tournament data based on your regular season predictions.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtE5o3T2IEfo"
      },
      "source": [
        "### Create an input layer with multiple columns\r\n",
        "\r\n",
        "In this exercise, you will look at a different way to create models with multiple inputs. This method only works for purely numeric data, but its a much simpler approach to making multi-variate neural networks.\r\n",
        "\r\n",
        "Now you have three numeric columns in the tournament dataset: 'seed_diff', 'home', and 'pred'. In this exercise, you will create a neural network that uses a single input layer to process all three of these numeric inputs.\r\n",
        "\r\n",
        "This model should have a single output to predict the tournament game score difference.\r\n",
        "\r\n",
        "```\r\n",
        "# Create an input layer with 3 columns\r\n",
        "input_tensor = Input((3,))\r\n",
        "\r\n",
        "# Pass it to a Dense layer with 1 unit\r\n",
        "output_tensor = Dense(1)(input_tensor)\r\n",
        "\r\n",
        "# Create a model\r\n",
        "model = Model(input_tensor, output_tensor)\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\r\n",
        "```\r\n",
        "*Now your model is ready to meet some data!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kojwyidJyjmv"
      },
      "source": [
        "### Fit the model\r\n",
        "\r\n",
        "Now that you've enriched the tournament dataset and built a model to make use of the new data, fit that model to the tournament data.\r\n",
        "\r\n",
        "Note that this model has only one input layer that is capable of handling all 3 inputs, so it's inputs and outputs do not need to be a list.\r\n",
        "\r\n",
        "Tournament games are split into a training set and a test set. The tournament games before 2010 are in the training set, and the ones after 2010 are in the test set\r\n",
        "\r\n",
        "```\r\n",
        "# Fit the model\r\n",
        "model.fit(games_tourney_train[['home', 'seed_diff', 'pred']],\r\n",
        "          games_tourney_train['score_diff'],\r\n",
        "          epochs=1,\r\n",
        "          verbose=True)\r\n",
        "```\r\n",
        "*In the next exercise, you'll see if our model is any good!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4zu1KISyjaU"
      },
      "source": [
        "### Evaluate the model\r\n",
        "\r\n",
        "Now that you've fit your model to the tournament training data, evaluate it on the tournament test data. Recall that the tournament test data contains games from after 2010.\r\n",
        "\r\n",
        "```\r\n",
        "# Evaluate the model on the games_tourney_test dataset\r\n",
        "print(model.evaluate(games_tourney_test[['home','seed_diff','prediction']],\r\n",
        "               games_tourney_test['score_diff'], verbose=False))\r\n",
        "```\r\n",
        "*Your model works pretty well on data in the future!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvGkBtawkOvP"
      },
      "source": [
        "# 4. Multiple Outputs\r\n",
        "\r\n",
        "In this chapter, you will build neural networks with multiple outputs, which can be used to solve regression problems with multiple targets. You will also build a model that solves a regression problem and a classification problem simultaneously. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeCQd51k43RZ"
      },
      "source": [
        "### Two-output models (Video)\r\n",
        "\r\n",
        "Transcript:\r\n",
        "\r\n",
        "1. Two-output models\r\n",
        "In this chapter, I will cover neural networks with 2 outputs. These sorts of networks make predictions for 2 targets at once. For example, you could use a single model to predict the scores of both teams in a basketball game or use a single model to predict both the score difference and the win/loss outcome of that game. To me, this is the most interesting chapter in the class, because it teaches you things that only neural networks can do. At the end of the chapter, I will show you how to make a single model that is both a classifier and a regressor.\r\n",
        "\r\n",
        "2. Simple model with 2 outputs\r\n",
        "To create a model with 2 outputs, we start with an input layer, as with all keras models. In this example, there is only one predictor, so I use an Input layer with one input. To make a 2 output model, I simply make a Dense layer with 2 units for the output layer. The model will now make 2 predictions! Contrast this model with models from previous chapters, which all had single outputs, and therefore Dense output layers with a single unit. The only difference between the 2 output model and the one output model is the size of the output layer.\r\n",
        "\r\n",
        "3. Simple model with 2 outputs\r\n",
        "The API for creating a 2-output model and compiling it is exactly the same as for a single output model. Wrap the input and the output tensors in your call to Model(), and then compile it using the adam optimizer and mean absolute error.\r\n",
        "\r\n",
        "4. Fitting a model with 2 outputs\r\n",
        "To fit a model with 2 outputs, you use a dataset with 2 columns for the y variable. In this case, the training set has the seed difference for the two teams, as well the team's scores for the game. The model's single input is seed difference, and the 2 outputs are the scores for each team. The fit call is then exactly the same as a single input, single output model. The difference is that the y variable has 2 columns now. This particular model takes a while to converge, so I use 500 epochs in the fit. For the exercises, you will use some additional data in the model that will help it converge faster.\r\n",
        "\r\n",
        "5. Inspecting a 2 output model\r\n",
        "Now that the model is fit, you can take a look at what it learned. The dense layer has two weights and two biases. The weights indicate that each additional unit of seed difference for the input data equals about .60 additional points for team 1 (and .60 fewer points for team 2). The bias, or intercept term for each team is about 70 points, indicating that we expect an average basketball team to score about 70 points in an average game. In other words, 2 teams with a 1 point seed difference would be expected to have a score of about 69 to 71, while 2 teams with a 10 point seed difference would be expected to have a score of about 64 to 76.\r\n",
        "\r\n",
        "6. Evaluating a model with 2 outputs\r\n",
        "Evaluating a model with two outputs is very similar to evaluating a model with 1 output, except you provide the evaluation function a dataset with 2 columns of data for the target. In this case, the model performs reasonably well on the test set, but in the exercises, you will add some more data to get better predictions.\r\n",
        "\r\n",
        "7. Let's practice!\r\n",
        "Now that I've shown you how to fit a model with 2 outputs, you can practice doing it yourself.\r\n",
        "\r\n",
        "Note: PDF available in the same folder - chapter4\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FmthJMo43N7"
      },
      "source": [
        "### Simple two-output model\r\n",
        "\r\n",
        "In this exercise, you will use the tournament data to build one model that makes two predictions: the scores of both teams in a given game. Your inputs will be the seed difference of the two teams, as well as the predicted score difference from the model you built in chapter 3.\r\n",
        "\r\n",
        "The output from your model will be the predicted score for team 1 as well as team 2. This is called \"multiple target regression\": one model making more than one prediction.\r\n",
        "\r\n",
        "```\r\n",
        "# Define the input\r\n",
        "input_tensor = Input(shape=(2,))\r\n",
        "\r\n",
        "# Define the output\r\n",
        "output_tensor = Dense(2)(input_tensor)\r\n",
        "\r\n",
        "# Create a model\r\n",
        "model = Model(input_tensor, output_tensor)\r\n",
        "\r\n",
        "# Compile the model\r\n",
        "model.compile(loss='mean_absolute_error', optimizer='adam')\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LyYmRk1n43Bi"
      },
      "source": [
        "### Fit a model with two outputs\r\n",
        "\r\n",
        "Now that you've defined your 2-output model, fit it to the tournament data. I've split the data into games_tourney_train and games_tourney_test, so use the training set to fit for now.\r\n",
        "\r\n",
        "This model will use the pre-tournament seeds, as well as your pre-tournament predictions from the regular season model you built previously in this course.\r\n",
        "\r\n",
        "As a reminder, this model will predict the scores of both teams.\r\n",
        "\r\n",
        "```\r\n",
        "model.fit(games_tourney_train[['seed_diff', 'pred']],\r\n",
        "  \t\t  games_tourney_train[['score_1', 'score_2']],\r\n",
        "  \t\t  verbose=True,\r\n",
        "          epochs=100,\r\n",
        "  \t\t  batch_size=16384)\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYK4M36R4291"
      },
      "source": [
        "### Inspect the model (I)\r\n",
        "\r\n",
        "Now that you've fit your model, let's take a look at it. You can use the .get_weights() method to inspect your model's weights.\r\n",
        "\r\n",
        "The input layer will have 4 weights: 2 for each input times 2 for each output.\r\n",
        "\r\n",
        "The output layer will have 2 weights, one for each output.\r\n",
        "\r\n",
        "```\r\n",
        "# Print the model's weights\r\n",
        "print(model.get_weights())\r\n",
        "\r\n",
        "# Print the column means of the training data\r\n",
        "print(games_tourney_train.mean())\r\n",
        "```\r\n",
        "*Did you notice that both output weights are about ~72? This is because, on average, a team will score about 72 points in the tournament.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BzCKlKL427k"
      },
      "source": [
        "### Evaluate the model\r\n",
        "\r\n",
        "Now that you've fit your model and inspected it's weights to make sure it makes sense, evaluate it on the tournament test set to see how well it performs on new data.\r\n",
        "\r\n",
        "```\r\n",
        "print(model.evaluate(games_tourney_test[['seed_diff', 'pred']],\r\n",
        "               games_tourney_test[['score_1', 'score_2']], verbose=False))\r\n",
        "```\r\n",
        "*This model is pretty accurate at predicting tournament scores!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na4RueJkvkFk"
      },
      "source": [
        "### Single model for classification and regression (Video)\r\n",
        "\r\n",
        "Transcript:\r\n",
        "\r\n",
        "1. Single model for classification and regression\r\n",
        "In this lesson, I will demonstrate how to build a simple model that performs both classification and regression.\r\n",
        "\r\n",
        "2. Build a simple regressor/classifier\r\n",
        "This is another example of a model with two outputs. In this case, however, rather than using two regression outputs, I have a regression output and a classification output. As before, I define the regression part of this model with a single input and a Dense output layer with a single unit. For the classification part of the model, I use the regression model prediction as input and then add another Dense output layer on top of it using the sigmoid activation, which will map the predicted score differences to probabilities that team 1 wins.\r\n",
        "\r\n",
        "3. Make a regressor/classifier model\r\n",
        "With two output models, each output needs its own loss function. For this model, I've specified two different loss functions, one for the regression model and one for the classification model. As with all the models in this course, I used adam for the optimizer.\r\n",
        "\r\n",
        "4. Fit the combination classifier/regressor\r\n",
        "To fit the combination classification/regression model, you must provide the y data as a list. Recall that this is similar to the way you built two input models in chapter 2. Use seed_difference as the only input to this model. For the regression output, I use score_difference, and for the classification output, I use whether or not team 1 won the game. I split both of these variables out from the training set and pass them to the fit method as a list. This model fits a bit more quickly than the last one, so I only use 100 epochs.\r\n",
        "\r\n",
        "5. Look at the model's weights\r\n",
        "This model's weight structure is a bit different from the last model, where both outputs were regression targets. The first layer has a weight of 1.24 and a bias of almost zero. This means that a 1 unit change in the teams' seed difference yields about 1.24 additional points in their score difference. So 2 teams with a seed difference of 1 would be expected to have team 1 win by 1.2 points. But 2 teams with a seed difference of 10 would be expected to have team 1 win by 12 points. The next layer maps predicted score difference to predicted win/loss. Recall that the final layer in the model uses sigmoid activation.\r\n",
        "\r\n",
        "6. Look at the model's weights\r\n",
        "You can manually calculate the final layer in the model for some example data, to get an understanding of how the model has learned to relate score difference to win probabilities. Scipy has a function called expit(), which is an efficient implementation of the sigmoid function. Let's manually calculate the win probability for 2 teams that are predicted to have a score difference of 1. First, multiply 1 by the weight for the final layer in the model: 0.14. Add the bias for the final layer: 0.0007. Since the bias is very close to zero, the result is still 0.14. Finally, we apply the sigmoid function to 0.14, which yields a prediction of 0.54. In other words, the model has learned that an expected score difference of 1 point is equal to an expected win probability of 54%.\r\n",
        "\r\n",
        "7. Evaluate the model on new data\r\n",
        "Finally, you can evaluate the model on new data. First, split the evaluation dataset into a regression target and a classification target, and provide the same list of 2 targets to the evaluate() method. This outputs 3 numbers now, instead of 1 as with the models we looked at in other chapters. The first number is the loss function used by the model, which is the sum of all the output losses. The second number is the loss for the regression part of the model, and the third number is the loss for the classification part of the model. So our model has a mean absolute error of 9.28 and a logloss of 0.58, which is pretty good, but I think you can do better with more data when you try for yourself.\r\n",
        "\r\n",
        "8. Now you try!\r\n",
        "Now you try fitting your own combination regression-classification model!\r\n",
        "\r\n",
        "Note: PDF available in the same folder - chapter4-1\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsNU0zZlvj8R"
      },
      "source": [
        "### Classification and regression in one model\r\n",
        "\r\n",
        "Now you will create a different kind of 2-output model. This time, you will predict the score difference, instead of both team's scores and then you will predict the probability that team 1 won the game. This is a pretty cool model: it is going to do both classification and regression!\r\n",
        "\r\n",
        "In this model, turn off the bias, or intercept for each layer. Your inputs (seed difference and predicted score difference) have a mean of very close to zero, and your outputs both have means that are close to zero, so your model shouldn't need the bias term to fit the data well.\r\n",
        "\r\n",
        "```\r\n",
        "# Create an input layer with 2 columns\r\n",
        "input_tensor = Input(shape=(2,))\r\n",
        "\r\n",
        "# Create the first output\r\n",
        "output_tensor_1 = Dense(1, activation='linear', use_bias=False)(input_tensor)\r\n",
        "\r\n",
        "# Create the second output (use the first output as input here)\r\n",
        "output_tensor_2 = Dense(1, activation='sigmoid', use_bias=False)(output_tensor_1)\r\n",
        "\r\n",
        "# Create a model with 2 outputs\r\n",
        "model = Model(input_tensor, [output_tensor_1, output_tensor_2])\r\n",
        "```\r\n",
        "*This kind of model is only possible with a neural network.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqVqUQw5vjyJ"
      },
      "source": [
        "### Compile and fit the model\r\n",
        "\r\n",
        "Now that you have a model with 2 outputs, compile it with 2 loss functions: mean absolute error (MAE) for 'score_diff' and binary cross-entropy (also known as logloss) for 'won'. Then fit the model with 'seed_diff' and 'pred' as inputs. For outputs, predict 'score_diff' and 'won'.\r\n",
        "\r\n",
        "This model can use the scores of the games to make sure that close games (small score diff) have lower win probabilities than blowouts (large score diff).\r\n",
        "\r\n",
        "The regression problem is easier than the classification problem because MAE punishes the model less for a loss due to random chance. For example, if score_diff is -1 and won is 0, that means team_1 had some bad luck and lost by a single free throw. The data for the easy problem helps the model find a solution to the hard problem.\r\n",
        "\r\n",
        "```\r\n",
        "# Import the Adam optimizer\r\n",
        "from keras.optimizers import Adam\r\n",
        "\r\n",
        "# Compile the model with 2 losses and the Adam optimzer with a higher learning rate\r\n",
        "model.compile(loss=['mean_absolute_error', 'binary_crossentropy'], optimizer=Adam(.01))\r\n",
        "\r\n",
        "# Fit the model to the tournament training data, with 2 inputs and 2 outputs\r\n",
        "model.fit(games_tourney_train[['seed_diff', 'pred']],\r\n",
        "          [games_tourney_train[['score_diff']], games_tourney_train[['won']]],\r\n",
        "          epochs=10,\r\n",
        "          verbose=True,\r\n",
        "          batch_size=16384)\r\n",
        "```\r\n",
        "*You just fit a model that is both a classifier and a regressor!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x2FIrEh424p"
      },
      "source": [
        "### Inspect the model (II)\r\n",
        "\r\n",
        "Now you should take a look at the weights for this model. In particular, note the last weight of the model. This weight converts the predicted score difference to a predicted win probability. If you multiply the predicted score difference by the last weight of the model and then apply the sigmoid function, you get the win probability of the game.\r\n",
        "\r\n",
        "```\r\n",
        "# Print the model weights\r\n",
        "print(model.get_weights())\r\n",
        "\r\n",
        "# Print the training data means\r\n",
        "print(games_tourney_train.mean())\r\n",
        "```\r\n",
        "```\r\n",
        "# Import the sigmoid function from scipy\r\n",
        "from scipy.special import expit as sigmoid\r\n",
        "\r\n",
        "# Weight from the model\r\n",
        "weight = 0.14\r\n",
        "\r\n",
        "# Print the approximate win probability of a predicted close game\r\n",
        "print(sigmoid(1 * weight))\r\n",
        "\r\n",
        "# Print the approximate win probability of a predicted blowout game\r\n",
        "print(sigmoid(10 * weight))\r\n",
        "```\r\n",
        "*So sigmoid(1 * 0.14) is 0.53, which represents a pretty close game and sigmoid(10 * 0.14) is 0.80, which represents a pretty likely win. In other words, if the model predicts a win of 1 point, it is less sure of the win than if it predicts 10 points. Who says neural networks are black boxes?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1bufoAPIJyw"
      },
      "source": [
        "### Evaluate on new data with two metrics\r\n",
        "\r\n",
        "Now that you've fit your model and inspected its weights to make sure they make sense, evaluate your model on the tournament test set to see how well it does on new data.\r\n",
        "\r\n",
        "Note that in this case, Keras will return 3 numbers: the first number will be the sum of both the loss functions, and then the next 2 numbers will be the loss functions you used when defining the model.\r\n",
        "\r\n",
        "```\r\n",
        "# Evaluate the model on new data\r\n",
        "print(model.evaluate(games_tourney_test[['seed_diff', 'pred']],\r\n",
        "               [games_tourney_test[['score_diff']], games_tourney_test[['won']]], verbose=False))\r\n",
        "```\r\n",
        "*Turns out you can have your cake and eat it too! This model is both a good regressor and a good classifier!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y40p2DRUIJpz"
      },
      "source": [
        "### Wrap-up (Video)\r\n",
        "\r\n",
        "Transcript:\r\n",
        "\r\n",
        "1. Wrap-up\r\n",
        "In this course, I've tried to focus on designing network topologies that can be used to solve interesting problems.\r\n",
        "\r\n",
        "2. So far...\r\n",
        "You learned how to build functional keras models, including advanced topics such as shared layers, categorical embeddings, multiple inputs, and multiple outputs. You can now build a model capable of solving a regression and a classification problem simultaneously.\r\n",
        "\r\n",
        "3. Shared layers\r\n",
        "In this final video, I'd like to discuss some real-world uses cases of what you've learned. Shared layers are incredibly useful when you want to compare two things. For example, we compared two basketball teams to decide how different they were in their ability to score points in a basketball game, using a shared embedding model. In academic research, shared models are known as \"siamese networks\", which are used to calculate things like document similarity, using shared embedding layer and a shared long-short-term memory layer (or LSTM layer), and then comparing the LSTM outputs. Since both documents are encoded with the same embedding layer and the same LSTM layer, the model learns a representation of the documents that can be used to compare them. Here are some links for further reading.\r\n",
        "\r\n",
        "4. Multiple inputs\r\n",
        "Multiple input networks are especially useful when you want to process different types of data within your model. For example, in our basketball models, we processed team IDs separately, using an embedding layer. For numeric data such as home vs away, we skipped the embedding step and passed it directly to the output. You can extend this concept to build a network that, for example, uses an LSTM to process text, a standard Dense layer to process numerics, and a convolutional layer (or CNN) to process images. I didn't cover LSTMs or CNNs in this course, but once you understand them, you can use this concept to make networks that understand both text and images!\r\n",
        "\r\n",
        "5. Multiple outputs\r\n",
        "The multiple output network you built in chapter 4 is the coolest model of the course. It can do both classification AND regression! I like this model a lot because the regression problem turns out to be a lot easier than the classification problem. In the regression problem, the neural network gets penalized less for random chance. For example, a team that wins by 1 point got really lucky, and the model can use that information. However, in the classification model, winning by 1 point is the same as winning by 10 points. I think it's pretty cool that we can use the output from the easier regression problem to help solve the more difficult classification problem.\r\n",
        "\r\n",
        "6. Skip connections\r\n",
        "Here's a final example that we didn't explicitly cover in the class, but that is trivially easy now that you know how to use a concatenate layer. In a paper called \"Visualizing the Loss Landscape of Neural Nets\", Li et al. propose a method called \"skip connections\" to simplify the optimization of neural networks. To summarize a very long and interesting paper, skip connections make it a lot easier for the adam optimizer to find the global minimum of the network's loss function. In Keras, implementing a skip connection is as simple as using the \"Concatenate\" layer to concatenate the inputs to the deep network's outputs, right before the final output layer.\r\n",
        "\r\n",
        "7. Best of luck!\r\n",
        "I hope you enjoyed taking a deep dive into the keras functional API with me, and that the flexibility of these neural networks will give you a lot of creative ways to solve your data science problems. Thank you for taking this course and best of luck building deep neural networks!\r\n",
        "\r\n",
        "Note: PDF available in the same folder - chapter4-2\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geyPGIWtkpMZ"
      },
      "source": [
        "# Datasets\r\n",
        "1. [Basketball data](https://assets.datacamp.com/production/repositories/2189/datasets/78cfc4f848041e10a64e72a9cd4f0a8e6f80ab21/basketball_data.zip)\r\n",
        "2. [Basketball models](https://assets.datacamp.com/production/repositories/2189/datasets/87408a711961f0d640f7c31faa9cfbf8248e6a23/basketball_models.zip)"
      ]
    }
  ]
}